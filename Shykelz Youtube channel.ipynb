{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "import dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Option et essentiel pour faire marcher le code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "scopes = [\n",
    "    \"https://www.googleapis.com/auth/spreadsheets\"\n",
    "]\n",
    "cred = Credentials.from_service_account_file(\"credential.json\",scopes=scopes)\n",
    "client = gspread.authorize(cred)\n",
    "\n",
    "sheets_id = \"1-eNcd2PWEHks-SaEB92pTFmTpk0FiG2ifZ7AdLavlPg\"\n",
    "workbook = client.open_by_key(sheets_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_sheet = workbook.worksheet(\"Mail adresses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "\n",
    "youtube = build(\n",
    "    api_service_name, api_version, developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_youtube(query:str, max_results:int):\n",
    "    \"\"\" Fait une recherche sur Youtube à partir de ce que tu veux.\n",
    "    \n",
    "    Coûte 100 unités par recherche.\n",
    "\n",
    "    Args : \n",
    "        query:str -> Ta recherche.\n",
    "        max_results:int -> Le nombre de vidéo que tu veux.\"\"\"\n",
    "    results = []\n",
    "    next_page_token = None\n",
    "\n",
    "    while len(results) < max_results:\n",
    "        # Limiter les résultats par requête pour rester en dessous de la limite max de 50\n",
    "        limit = min(50, max_results - len(results))\n",
    "\n",
    "        # Effectuer la requête\n",
    "        request = youtube.search().list(\n",
    "            q=query,\n",
    "            part='snippet',\n",
    "            maxResults=limit,\n",
    "            type='video',\n",
    "            pageToken=next_page_token,\n",
    "            order = \"viewCount\",\n",
    "            publishedAfter = \"2024-01-01T00:00:00Z\"\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        # Ajouter les résultats\n",
    "        results.extend(response.get('items', []))\n",
    "        \n",
    "        # Récupérer le token pour la page suivante\n",
    "        next_page_token = response.get('nextPageToken')\n",
    "        \n",
    "        # Sortir de la boucle si aucune page suivante n'existe\n",
    "        if not next_page_token:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "def fetch_videos(id:str):\n",
    "    \"\"\" Cherche parmis tous les identifiants donnés en paramètres les informations des vidéos\n",
    "    \n",
    "    Coûte 1 unité par recherche\n",
    "    \n",
    "    Args :\n",
    "        id:str -> identifiant de vidéo\n",
    "\n",
    "    return string id video    \n",
    "    \"\"\"\n",
    "    request = youtube.videos().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=id\n",
    "        )\n",
    "    # ytb_search(query = query)\n",
    "    return request.execute()\n",
    "\n",
    "def channel_search(id_channel:str):\n",
    "    \"\"\"Voir le nombre d'abonné\n",
    "    \n",
    "    100 de quota.\n",
    "    \"\"\"\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=id_channel\n",
    "    )\n",
    "    return request.execute()\n",
    "\n",
    "def channel_videos(id_channel:str):\n",
    "    \"\"\"\n",
    "    1 de quota\n",
    "    \"\"\"\n",
    "    request = youtube.search().list(\n",
    "        part=\"snippet\",\n",
    "        maxResults=50,\n",
    "        order=\"date\",\n",
    "        type=\"video\",\n",
    "        channelId=id_channel\n",
    "    )\n",
    "    return request.execute()\n",
    "\n",
    "def fetch_videos_id(query:str,max_results:int = 100):\n",
    "    \"\"\"Search video ids from the def ytb_search\n",
    "    Args : \n",
    "        raw_json_search:dict -> Must be the default json of ytb_search\n",
    "    \"\"\"\n",
    "    youtube_search_json = search_youtube(query=query,max_results=max_results)\n",
    "    mail = mail_sheet.col_values(2)\n",
    "\n",
    "    \n",
    "    channel_Ids = []\n",
    "    unique_channel_ids = []\n",
    "    video_ids = \"\"\n",
    "    \n",
    "    for x in range(0,max_results):\n",
    "        channel_Ids.append(youtube_search_json[x][\"snippet\"][\"channelId\"])\n",
    "    \n",
    "    [unique_channel_ids.append(channel_Id) for channel_Id in channel_Ids if channel_Id not in unique_channel_ids]\n",
    "\n",
    "    channel_id_search = []\n",
    "    channel_videos_list = []\n",
    "    for unique_channel_id in unique_channel_ids:\n",
    "        if unique_channel_id not in mail:\n",
    "            channel_id_search.append(channel_search(unique_channel_id))\n",
    "            channel_videos_list.append(channel_videos(unique_channel_id))\n",
    "        else:\n",
    "            pass\n",
    "    for r in range(0,len(channel_id_search)):\n",
    "        try:    \n",
    "            channel_id_v = channel_videos_list[r][\"items\"][0][\"snippet\"][\"channelId\"]\n",
    "            channel_id_s = channel_id_search[r][\"items\"][0][\"id\"]\n",
    "            subscriberCount = int(channel_id_search[r][\"items\"][0][\"statistics\"][\"subscriberCount\"])\n",
    "        except TypeError:\n",
    "            pass\n",
    "        \n",
    "        publishedAt = channel_videos_list[r][\"items\"][0][\"snippet\"][\"publishedAt\"]\n",
    "        \n",
    "        date_obj = datetime.strptime(publishedAt, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        # Calcul de la différence de temps\n",
    "        diff = datetime.now() - date_obj\n",
    "        \n",
    "        # Vérification si la différence est inférieure à 7 jours\n",
    "        if channel_id_s == channel_id_v:\n",
    "            if subscriberCount > 1000:\n",
    "                if diff < timedelta(weeks=2.5):\n",
    "                    video_ids += channel_videos_list[r][\"items\"][0][\"id\"][\"videoId\"] + \",\"\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "    return video_ids\n",
    "\n",
    "\n",
    "def search_multiple_video_id(video_ids:str):\n",
    "    \"\"\" Split les id de video en liste pour qu'elle y ait 50 videoId par liste et ainsi pouvoir faire marcher fetch_video_id\n",
    "        Si je ne fais pas ça, il y a une limitation de 50 vidéos, au delà, cela ne marchera pas\n",
    "    \n",
    "    Besoin fetch_videos_id \"\"\"\n",
    "    ids_split_list = video_ids.split(\",\")\n",
    "    nb = 0\n",
    "    next_nb = 50\n",
    "    json_raw_video_id = []\n",
    "    while nb != len(ids_split_list):\n",
    "        if len(ids_split_list) > 50:\n",
    "            id_split = ids_split_list[nb:next_nb]\n",
    "            json_raw_video_id.append(fetch_videos(id=id_split))\n",
    "        \n",
    "        nb += len(id_split)\n",
    "        next_nb += len(id_split)\n",
    "        \n",
    "    return json_raw_video_id\n",
    "\n",
    "def getmail_json(query:str,max_results:int = 100):\n",
    "    query_list = query.split(\",\") # Transforme la chaine de caractère en liste.\n",
    "\n",
    "    if len(query_list) > 50:\n",
    "        json_video = search_multiple_video_id(fetch_videos(id=query_list))\n",
    "    else:\n",
    "        json_video = fetch_videos(id=query_list)\n",
    "\n",
    "    mail_list = []\n",
    "    items = json_video[\"items\"]\n",
    "\n",
    "    for video_count in range(0,len(items)):\n",
    "        channelTitle = items[video_count][\"snippet\"][\"channelTitle\"]\n",
    "        if \"VEVO\" in channelTitle or \"Vevo\" in channelTitle:\n",
    "            pass\n",
    "        else:\n",
    "            text = items[video_count][\"snippet\"][\"description\"]\n",
    "            channelId = items[video_count][\"snippet\"][\"channelId\"]\n",
    "\n",
    "            # Motif regex pour capturer une adresse email\n",
    "            email_pattern = r'\\b[\\w.-]+@[a-zA-Z-]+\\.[a-zA-Z.]{2,}\\b'\n",
    "\n",
    "            # Recherche de l'adresse email\n",
    "            try:\n",
    "                match = re.search(email_pattern, text).group()\n",
    "                mail_list.append({'channelTitle' : channelTitle,\n",
    "                'channelId' : channelId,\n",
    "                'channel_mail' : match,\n",
    "                'research' : query,\n",
    "            })\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    return mail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Changer la manière de trier les vidéos -> Faire par rapport au viewcount\n",
    "# TODO : Si possible regarder en fonction du titre de la chaine\n",
    "# TODO : Filter par date\n",
    "# TODO : Rajoutez des stats sur les chaînes avec les ID -> utilisé youtube.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_id = fetch_videos_id(\"Luther type beat\", max_results=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_dict = getmail_json(videos_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mail_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_sheet = workbook.worksheet(\"Mail adresses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_excel(mail_dict:list):\n",
    "    mail = mail_sheet.col_values(2)\n",
    "    nb = 0\n",
    "    for row in mail_dict:\n",
    "        channel_id = row[\"channelId\"]\n",
    "        if channel_id not in mail:\n",
    "            nb += 1\n",
    "            mail_sheet.insert_row([row[\"channelTitle\"], row[\"channelId\"], row[\"channel_mail\"]], 2)\n",
    "        else:\n",
    "            pass\n",
    "    return f\"Il y a {nb} d'artiste qui ont été ajouté sur {len(mail_dict)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Il y a 4 d'artiste qui ont été ajouté sur 4\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_to_excel(mail_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essaie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = youtube.search().list(\n",
    "    q=\"Travis Scott Type Beat\",\n",
    "    part='snippet',\n",
    "    maxResults=200,\n",
    "    type='video',\n",
    "    order = \"viewCount\",\n",
    "    publishedAfter = \"2024-04-01T00:00:00Z\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "central_split = central.split(\",\")\n",
    "len(central_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_dict = getmail_json(central)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Il y a 28 d'artiste qui ont été ajouté sur 28\""
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_to_excel(mail_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
